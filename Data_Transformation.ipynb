{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "20821e6b-25b2-436f-9aa4-40858962bbb2",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "75e4d169-87c4-41c7-a49d-ee4eb42bad42",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, count, when, regexp_extract, regexp_replace, concat_ws, array\n",
    "from pyspark.sql.types import TimestampType\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7aced713-2628-4f91-b7fc-8ba54e67d3a9",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#Load dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "086612f6-228d-447a-a8fb-98934f3338fc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "##load pin data\n",
    "file_location = \"/mnt/pinterest_s3/topics/12256357c821.pin/partition=0/*.json\" \n",
    "file_type = \"json\"\n",
    "# Ask Spark to infer the schema\n",
    "infer_schema = \"true\"\n",
    "# Read in JSONs from mounted S3 bucket\n",
    "df_pin = spark.read.format(file_type) \\\n",
    ".option(\"inferSchema\", infer_schema) \\\n",
    ".load(file_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9b90dab0-36f6-4b2c-8cb4-91d0571c4467",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## load geo\n",
    "file_location = \"/mnt/pinterest_s3/topics/12256357c821.geo/partition=0/*.json\" \n",
    "file_type = \"json\"\n",
    "# Ask Spark to infer the schema\n",
    "infer_schema = \"true\"\n",
    "# Read in JSONs from mounted S3 bucket\n",
    "df_geo = spark.read.format(file_type) \\\n",
    ".option(\"inferSchema\", infer_schema) \\\n",
    ".load(file_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "50c8eafe-d47d-4463-9467-01528e7a6b47",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## load user data\n",
    "file_location = \"/mnt/pinterest_s3/topics/12256357c821.user/partition=0/*.json\" \n",
    "file_type = \"json\"\n",
    "# Ask Spark to infer the schema\n",
    "infer_schema = \"true\"\n",
    "# Read in JSONs from mounted S3 bucket\n",
    "df_user = spark.read.format(file_type) \\\n",
    ".option(\"inferSchema\", infer_schema) \\\n",
    ".load(file_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4c5d069b-85c3-4a5b-8f8d-04f12ded5619",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Pin Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5ca876f5-ac6b-4d20-a026-c4902b233a6d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Task 1  Replace empty entries and entries with no relevant data in each column with Nones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "03ae1b91-e527-41bc-b14c-bcb0fe6dc82f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### approach--> inspect each column and understand the data, firstly by figuring the unique values and seeing if everything is inline\n",
    "1. category column has no missing values --> df_pin.select('category').distinct().show() \n",
    "2. description since there are more unique values I decided to take a difference approach here --> df_pin.groupBy('description').agg(count('*').alias('count')).orderBy('count', ascending=False).show()--> \"No description av\"\n",
    "3. downloaded seems to have few distinct values and therefore df_pin.select('downloaded').distinct().show().orderBy('count', ascending=False).show() is useful here 0,1 where the only unique values\n",
    "4. follower count --> df_pin.select(regexp_extract(col(\"follower_count\"), \"([a-zA-Z,.]+)\", 1).alias(\"letters\")).distinct().show() this will essentially help us with future tasks as well as checking what values are in the column\n",
    "5. image_src --> pattern = r\"^https://i\\.pinimg\\.com\"  Filter rows where \"image_src\" doesn't match the pattern non_matching_entries = df_pin.filter(~col(\"image_src\").rlike(pattern)) non_matching_entries.select(\"image_src\").distinct().show()--> one entry is wrong so will replace it with none \n",
    "6. poster_name df_pin.groupBy('poster_name').agg(count('*').alias('count')).show().orderBy('count', ascending=False).show()\n",
    "7. save_location similar pattern filteration pattern = r\"^Local save in /data/\\w+$\" gave 4 values but the difference is that post data/ we had a \"-\" between words which don't represent an unusual value\n",
    "8. tag_list -->  df_pin.groupBy('tag_list').agg(count('*').alias('count')).show().orderBy('count', ascending=False).show()--> 'N,o, ,T,a,g,s, ,A'\n",
    "9. title --> df_pin.groupBy('title').agg(count('*').alias('count')).show().orderBy('count', ascending=False).show() --> No Title Data Ava\n",
    "10. unique id check for pattern uuid_pattern = r\"^[a-fA-F0-9]{8}-[a-fA-F0-9]{4}-[a-fA-F0-9]{4}-[a-fA-F0-9]{4}-[a-fA-F0-9]{12}$\" none returned\n",
    "therefore, there are now empty entries or entries with non-relevant data to give the value none"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "be87f9aa-21b0-456e-b643-dccd5b22cfd2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Replace \"User Info Error\" with None in the \"poster_name\" column\n",
    "df_pin = df_pin.withColumn(\n",
    "    \"poster_name\",\n",
    "    when(col(\"poster_name\").rlike(\"(?i)User Info Error\"), None).otherwise(col(\"poster_name\"))\n",
    ")\n",
    "\n",
    "# Replace \"No Title Data Avai\" with None in the \"title\" column\n",
    "df_pin = df_pin.withColumn(\n",
    "    \"title\",\n",
    "    when(col(\"title\").rlike(\"(?i)No Title Data\"), None).otherwise(col(\"title\"))\n",
    ")\n",
    "\n",
    "# Replace \"User\" with None in the \"follower_count\" column\n",
    "df_pin = df_pin.withColumn(\n",
    "    \"follower_count\",\n",
    "    when(col(\"follower_count\").rlike(\"(?i)User\"), None).otherwise(col(\"follower_count\"))\n",
    ")\n",
    "\n",
    "# Replace \"No description available\" with None in the \"description\" column\n",
    "df_pin = df_pin.withColumn(\n",
    "    \"description\",\n",
    "    when(col(\"description\").rlike(\"(?i)No description av\"), None).otherwise(col(\"description\"))\n",
    ")\n",
    "\n",
    "# Replace entries in the \"tag_list\" column that contain \"N,o, ,T,a,g,s, ,A\" with None\n",
    "df_pin = df_pin.withColumn(\n",
    "    \"tag_list\",\n",
    "    when(col('tag_list').rlike(\"(?i)N,o, ,T,a,g,s, ,A\"), None).otherwise(col(\"tag_list\"))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "902ebd17-0893-411b-8ea9-710ad3b3bbf2",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Task 2 \n",
    "- Perform the necessary transformations on the follower_count to ensure every entry is a number. Make sure the data type of this column is an int.\n",
    "- approach\n",
    "  1. data has already been cleaned to only include numbers or numbers followed by \"k\" or \"M\"\n",
    "  2. strip K and M and mulitply by 1000 and 1,000,000 respectively\n",
    "  3. transform all strings into integers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9885c649-42e7-465c-9eef-0d32453a3dad",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_pin = df_pin.withColumn(\n",
    "    \"follower_count\", \n",
    "    when(df_pin.follower_count.endswith(\"k\"), \n",
    "         regexp_replace(df_pin.follower_count, \"k\", \"\").cast(\"int\") * 1000)\n",
    "    .otherwise(\n",
    "        when(df_pin.follower_count.endswith(\"M\"), \n",
    "             regexp_replace(df_pin.follower_count, \"M\", \"\").cast(\"int\") * 1000000)\n",
    "        .otherwise(df_pin.follower_count.cast(\"int\"))\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3fa1902f-c890-47b8-965c-7a8e6632706c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Task 3\n",
    "- Clean the data in the save_location column to include only the save location path\n",
    "- Approach \n",
    "  1. remove \"Local save in \" from save_location to just show pathname \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cd03f24f-6285-4c1f-b095-eb9c20f1029d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_pin=df_pin.withColumn(\n",
    "    \"save_location\",\n",
    "    regexp_replace(df_pin.save_location,\"Local save in\",\"\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "950ba784-368b-4cf1-b77c-aac5631bae88",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Final Cleaning\n",
    "- Rename the index column to ind.\n",
    "- Reorder the DataFrame columns to have the following column order:\n",
    "  1. ind\n",
    "  2. unique_id\n",
    "  3. title\n",
    "  4. description\n",
    "  5. follower_count\n",
    "  6. poster_name\n",
    "  7. tag_list \n",
    "  8. is_image_or_video\n",
    "  9. image_src\n",
    "  10. save_location\n",
    "  11. category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b32687da-d6e6-44f4-934e-33cdc0c327d6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## change name of index to ind\n",
    "df_pin = df_pin.withColumnRenamed(\"index\", \"ind\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6436670e-630f-4c03-8314-66c2b2c9a12c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## reorder df columns\n",
    "df_pin = df_pin.select(\n",
    "    \"ind\",\n",
    "    \"unique_id\",\n",
    "    \"title\",\n",
    "    \"description\",\n",
    "    \"follower_count\",\n",
    "    \"poster_name\",\n",
    "    \"tag_list\",\n",
    "    \"is_image_or_video\",\n",
    "    \"image_src\",\n",
    "    \"save_location\",\n",
    "    \"category\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c898f295-18f5-4d54-b179-3ddbe28dfc6e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# df_pin.write.saveAsTable(\"pin_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "346d72ce-7e73-4de3-a8a6-01048f594dca",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Geo Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2041b3eb-502b-4efa-a44b-2616abe1b8e3",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Task 1 \n",
    "- Create a new column coordinates that contains an array based on the latitude and longitude columns and drop latitude and logitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d5af8046-3be6-4c55-ae3c-2ce87b6b3e1e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_geo=df_geo.withColumn(\"coordinates\",array(\"latitude\",\"longitude\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "93b2d62f-1fa2-4091-a1f2-7849c7eb3184",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_geo=df_geo.drop(\"latitude\")\n",
    "df_geo=df_geo.drop(\"longitude\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "751b8562-5b35-4ba5-b990-7b799a692b5c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Task 2 \n",
    "- Convert the timestamp column from a string to a timestamp data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "81d6f09a-502b-4bc3-8e3d-ebe3920ca126",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_geo = df_geo.withColumn(\"timestamp\", col(\"timestamp\").cast(TimestampType()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bd00e03f-3eb6-4d57-8d3a-bf8bb771ef1c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Final Cleaning\n",
    "- reorder the dataframe columns to have the following column order: \n",
    "  1. ind \n",
    "  2. country\n",
    "  3. coordinates\n",
    "  4. timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0796b87e-7124-4419-a905-e062e7f4a173",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n",
       "<span class=\"ansi-red-fg\">NameError</span>                                 Traceback (most recent call last)\n",
       "<span class=\"ansi-green-fg\">&lt;command-1885759062461495&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n",
       "<span class=\"ansi-green-fg\">----&gt; 1</span><span class=\"ansi-red-fg\"> df_geo= df_geo.select(\n",
       "</span><span class=\"ansi-green-intense-fg ansi-bold\">      2</span>     <span class=\"ansi-blue-fg\">&#34;ind&#34;</span><span class=\"ansi-blue-fg\">,</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">      3</span>     <span class=\"ansi-blue-fg\">&#34;country&#34;</span><span class=\"ansi-blue-fg\">,</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">      4</span>     <span class=\"ansi-blue-fg\">&#34;coordinates&#34;</span><span class=\"ansi-blue-fg\">,</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">      5</span>     <span class=\"ansi-blue-fg\">&#34;timestamp&#34;</span>\n",
       "\n",
       "<span class=\"ansi-red-fg\">NameError</span>: name &#39;df_geo&#39; is not defined</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">NameError</span>                                 Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-1885759062461495&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-fg\">----&gt; 1</span><span class=\"ansi-red-fg\"> df_geo= df_geo.select(\n</span><span class=\"ansi-green-intense-fg ansi-bold\">      2</span>     <span class=\"ansi-blue-fg\">&#34;ind&#34;</span><span class=\"ansi-blue-fg\">,</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      3</span>     <span class=\"ansi-blue-fg\">&#34;country&#34;</span><span class=\"ansi-blue-fg\">,</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      4</span>     <span class=\"ansi-blue-fg\">&#34;coordinates&#34;</span><span class=\"ansi-blue-fg\">,</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      5</span>     <span class=\"ansi-blue-fg\">&#34;timestamp&#34;</span>\n\n<span class=\"ansi-red-fg\">NameError</span>: name &#39;df_geo&#39; is not defined</div>",
       "errorSummary": "<span class=\"ansi-red-fg\">NameError</span>: name &#39;df_geo&#39; is not defined",
       "errorTraceType": "html",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_geo= df_geo.select(\n",
    "    \"ind\",\n",
    "    \"country\",\n",
    "    \"coordinates\",\n",
    "    \"timestamp\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bba3e6d6-bb46-4011-b985-08fce1a64547",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# df_geo.write.saveAsTable(\"geo_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f57ae012-74e1-4a06-9763-bb15cf3f41ae",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# User Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "27123ffa-3e3f-4196-bec0-1cd2db236fa2",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Task 1 \n",
    "- Create a new column user_name that concatenates the information found in the first_name and last_name columns and drop first_name and last_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "78fa663d-4260-4ff6-8949-4f4a31779a89",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_user = df_user.withColumn(\"user_name\", concat_ws(\" \", \"first_name\", \"last_name\"))\n",
    "df_user=df_user.drop(\"first_name\")\n",
    "df_user=df_user.drop(\"last_name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ff9490d3-8392-4e7b-9c89-a2fd6cbf9a03",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Task 2\n",
    "- Convert the date_joined column from a string to a timestamp data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4a458c28-6074-42e3-a60f-91e95bd8a127",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_user=df_user.withColumn(\"date_joined\",col(\"date_joined\").cast(TimestampType()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "44f43f7d-5039-4653-8e30-d0997d93864e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Final Cleaning\n",
    "- Reorder the DataFrame columns to have the following column order\n",
    "  1. ind \n",
    "  2. user_name\n",
    "  3. age\n",
    "  4. date_joined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d6569ef2-6e91-4f33-a560-05c9de449497",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_user=df_user.select(\n",
    "    \"ind\",\n",
    "    \"user_name\",\n",
    "    \"age\",\n",
    "    \"date_joined\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b7442290-a4d1-4688-afd8-d920679db712",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# df_user.write.mode('overwrite').saveAsTable(\"user_data\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Data_Transformation",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
